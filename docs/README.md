# ğŸ“š Job Hunter Engine - Developer Documentation

> **For Backend Developers** â€” Everything you need to understand, configure, and extend the Job Hunter Engine.

---

## ğŸ¯ What is This?

**Job Hunter Engine** is a **leads generation** backend system that:
1. **Scrapes** job listings from 8+ platforms (LinkedIn, Naukri, Indeed, etc.)
2. **Filters** jobs based on configurable criteria (roles, salary, experience)
3. **Scores** jobs using AI (Gemini/OpenAI) to prioritize best opportunities
4. **Generates leads** â€” curated job listings ready for manual review and application

> âš ï¸ **Note**: This is a leads generation tool, NOT an auto-apply bot. It finds and scores jobs; you apply manually.

It's designed for aggressive job hunting targeting **PE2 (Platform Engineer 2)** and mid-level DevOps/SRE roles.

---

## ğŸ“‘ Documentation Index

| Document | Description |
|----------|-------------|
| [ğŸš€ Getting Started](./01-getting-started.md) | Database setup, API keys, first run |
| [âš™ï¸ Configuration Guide](./02-configuration.md) | All configurable settings explained |
| [ğŸ” Search Filters](./03-search-filters.md) | How to customize job filtering |
| [ğŸ¤– AI Scoring](./04-ai-scoring.md) | Understanding the AI scoring system |
| [ğŸ—„ï¸ Database Schema](./05-database-schema.md) | Tables, functions, and queries |
| [ğŸ”Œ Platform Scrapers](./06-platform-scrapers.md) | Adding/modifying job scrapers |
| [ğŸ“Š Building a UI](./07-building-ui.md) | How to build a frontend for this engine |

---

## âš¡ Quick Start (TL;DR)

```bash
# 1. Clone and install
npm install
pip install -r requirements.txt

# 2. Copy and configure environment
cp .env.example .env
# Edit .env with your keys (see docs/01-getting-started.md)

# 3. Initialize database (run in Supabase SQL Editor)
# Copy contents of scripts/init-db.sql

# 4. Run the engine
npm start
```

---

## ğŸ—ï¸ Project Structure

```
engine/
â”œâ”€â”€ config/                 # âš™ï¸ Configuration files
â”‚   â”œâ”€â”€ ai.js              # AI provider settings (Gemini/OpenAI)
â”‚   â”œâ”€â”€ database.js        # PostgreSQL connection
â”‚   â”œâ”€â”€ platforms.js       # Scraper platform configs
â”‚   â””â”€â”€ search-filters.js  # Job filtering rules â† EDIT THIS
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ orchestrator/      # Main cron job runner
â”‚   â”œâ”€â”€ scrapers/          # Job scrapers (one per platform)
â”‚   â”œâ”€â”€ storage/           # Database repositories
â”‚   â”œâ”€â”€ scorer/            # AI scoring logic (Python)
â”‚   â”œâ”€â”€ sync/              # Google Sheets sync (optional)
â”‚   â””â”€â”€ utils/             # Logging and utilities
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ init-db.sql        # Database initialization script
â”‚
â”œâ”€â”€ logs/                   # Application logs
â”œâ”€â”€ docs/                   # ğŸ“š You are here
â””â”€â”€ package.json
```

---

## ğŸ”‘ Key Files to Know

| File | Purpose | When to Edit |
|------|---------|--------------|
| `config/search-filters.js` | Job filtering rules | Customize roles, salary, keywords |
| `config/ai.js` | AI scoring settings | Change thresholds, candidate profile |
| `config/platforms.js` | Scraper configurations | Enable/disable platforms, change search params |
| `scripts/init-db.sql` | Database schema | Adding new tables/columns |
| `.env` | Secrets & credentials | API keys, database URL |

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| **Runtime** | Node.js (scrapers, orchestrator) |
| **AI Scoring** | Python (Gemini/OpenAI) |
| **Database** | PostgreSQL (Supabase) |
| **Scheduler** | node-cron |
| **Optional** | Google Sheets sync |

---

## ğŸ“ Need Help?

1. **Check the logs** â€” `logs/app.log`, `logs/errors.log`
2. **Read the specific doc** â€” Use the documentation index above
3. **Inspect the database** â€” Supabase Dashboard â†’ SQL Editor

---

*Last updated: January 2026*
